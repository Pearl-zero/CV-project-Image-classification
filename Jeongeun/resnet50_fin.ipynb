{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요한 라이브러리 임포트\n",
    " \n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import f1_score\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 시드 고정: 결과 재현성을 위해 시드를 고정\n",
    "\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED) # 해시 시드 고정\n",
    "random.seed(SEED) # 파이썬 랜덤 시드 고정\n",
    "np.random.seed(SEED) # NumPy 랜덤 시드 고정\n",
    "torch.manual_seed(SEED) # PyTorch CPU 시드 고정\n",
    "torch.cuda.manual_seed(SEED) # PyTorch CUDA 시드 고정\n",
    "torch.cuda.manual_seed_all(SEED) # 모든 GPU에 대한 PyTorch CUDA 시드 고정\n",
    "torch.backends.cudnn.benchmark = True # CUDA의 성능 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#라벨 스무딩\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            # true_dist = pred.data.clone()\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스를 정의\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None):\n",
    "        self.df = pd.read_csv(csv).values # CSV 파일에서 데이터 로드\n",
    "        self.path = path # 이미지 파일 경로\n",
    "        self.transform = transform # 데이터 변환 함수\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) # 데이터셋의 길이 반환\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx] # 이미지 이름과 타겟 레이블 추출\n",
    "        img = np.array(Image.open(os.path.join(self.path, name))) # 이미지 로드\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image'] # 변환 적용\n",
    "        return img, target # 이미지와 레이블 반환\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 크기 설정\n",
    "img_size = 224\n",
    "\n",
    "# augmentation을 위한 transform 코드 (훈련 데이터용)\n",
    "trn_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),  # 이미지 크기 조정\n",
    "    A.PadIfNeeded(min_height=600, min_width=600, border_mode=cv2.BORDER_CONSTANT, value=(0, 0, 0), p=1.0),  # 필요시 패딩 추가\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # 정규화\n",
    "    ToTensorV2(),  # PyTorch 텐서로 변환\n",
    "])\n",
    "\n",
    "# test image 변환을 위한 transform 코드 (검증 데이터용)\n",
    "tst_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),  # 이미지 크기 조정\n",
    "    A.PadIfNeeded(min_height=600, min_width=600, border_mode=cv2.BORDER_CONSTANT, value=(0, 0, 0), p=1.0),  # 필요시 패딩 추가\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # 정규화\n",
    "    ToTensorV2(),  # PyTorch 텐서로 변환\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 정의\n",
    "full_dataset = ImageDataset(\"data2/train2.csv\", \"data2/train\", transform=trn_transform)\n",
    "\n",
    "# 데이터셋 크기 및 분할\n",
    "dataset_size = len(full_dataset)\n",
    "train_ratio = 0.8\n",
    "train_size = int(train_ratio * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "# 전체 인덱스를 생성하고 섞기\n",
    "indices = list(range(dataset_size))\n",
    "random.seed(42)  # 랜덤 시드 고정\n",
    "random.shuffle(indices)\n",
    "\n",
    "# 섞인 인덱스를 사용하여 데이터셋 분할\n",
    "train_indices = indices[:train_size]\n",
    "val_indices = indices[train_size:]\n",
    "\n",
    "# 훈련 및 검증 데이터셋 생성\n",
    "trn_dataset = torch.utils.data.Subset(full_dataset, train_indices)\n",
    "val_dataset = torch.utils.data.Subset(full_dataset, val_indices)\n",
    "\n",
    "# DataLoader 정의\n",
    "BATCH_SIZE = 32\n",
    "num_workers = 0\n",
    "\n",
    "trn_loader = DataLoader(trn_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# 데이터셋 크기 출력\n",
    "print(\"Full dataset size:\", dataset_size)\n",
    "print(\"Training dataset size:\", len(trn_dataset))\n",
    "print(\"Validation dataset size:\", len(val_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 모델 설정\n",
    "model_name = 'resnet50' #모델명 입력\n",
    "model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "\n",
    "# 손실 함수 및 옵티마이저 설정\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = LabelSmoothingLoss(classes=17, smoothing=0.1)\n",
    "\n",
    "# 학습률 스케줄러 설정\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# 초기 학습률 설정\n",
    "scheduler.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 로깅 함수\n",
    "def log_results(epoch, ret):\n",
    "    log = f\"Epoch: {epoch}\\n\"\n",
    "    for k, v in ret.items():\n",
    "        log += f\"{k}: {v:.4f}\\n\"\n",
    "    print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에폭당 학습을 위한 함수\n",
    "\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    model.train() # 모델을 학습 모드로 설정\n",
    "    train_loss = 0\n",
    "    preds_list = [] # 예측 결과 리스트 초기화\n",
    "    targets_list = [] # 타겟 리스트 초기화\n",
    "\n",
    "    pbar = tqdm(loader) # 진행 상황을 표시하기 위한 tqdm\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device) # 이미지 텐서를 지정한 장치로 이동\n",
    "        targets = targets.to(device) # 타겟 텐서를 지정한 장치로 이동\n",
    "\n",
    "        model.zero_grad(set_to_none=True) # 그래디언트 초기화\n",
    "\n",
    "        preds = model(image) # 모델 예측\n",
    "        loss = loss_fn(preds, targets) # 손실 계산\n",
    "        loss.backward() # 역전파\n",
    "        optimizer.step() # 최적화 단계\n",
    "\n",
    "        train_loss += loss.item() # 손실 누적\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy()) # 예측 결과 추가\n",
    "        targets_list.extend(targets.detach().cpu().numpy()) # 타겟 추가\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\") # 진행 바에 손실 출력\n",
    "\n",
    "    train_loss /= len(loader) # 평균 손실 계산\n",
    "    train_acc = accuracy_score(targets_list, preds_list) # 정확도 계산\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro') # F1 점수 계산\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss, # 평균 손실\n",
    "        \"train_acc\": train_acc, # 정확도\n",
    "        \"train_f1\": train_f1, # F1 점수\n",
    "    }\n",
    "\n",
    "    return ret # 결과 반환\n",
    "\n",
    "def validation(model, val_loader, loss_fn):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for val_images, val_labels in val_loader:\n",
    "            val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
    "            val_outputs = model(val_images)\n",
    "            loss = loss_fn(val_outputs, val_labels)\n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(val_outputs.argmax(dim=1).cpu().numpy())\n",
    "            targets_list.extend(val_labels.cpu().numpy())\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "    \n",
    "    return val_loss, val_acc, val_f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 및 검증 루프\n",
    "\n",
    "EPOCHS = 100\n",
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "early_stop_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # 1. 한 epoch 동안 학습 수행\n",
    "    train_results = train_one_epoch(trn_loader, model, optimizer, loss_fn, device)\n",
    "    # 2. 검증 수행\n",
    "    val_loss, val_accuracy, val_f1 = validation(model, val_loader, loss_fn)\n",
    "\n",
    "    # 3. 학습 결과 출력\n",
    "    log_results(epoch + 1, {\n",
    "        'train_loss': train_results['train_loss'],\n",
    "        'train_acc': train_results['train_acc'],\n",
    "        'train_f1': train_results['train_f1'],\n",
    "        'val_loss': val_loss,\n",
    "        'val_acc': val_accuracy,\n",
    "        'val_f1': val_f1\n",
    "    })\n",
    "    \n",
    "    # 4. 학습률 스케줄러 업데이트\n",
    "    scheduler.step()\n",
    "    \n",
    "    # 조기 종료 조건\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), f\"./model_resnet50fin_best.pt\")\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "\n",
    "    if early_stop_counter >= patience:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "\n",
    "    \n",
    "# 마지막 모델 저장\n",
    "torch.save(model.state_dict(), f\"./model_resnet50fin_last.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋 로드\n",
    "tst_dataset = ImageDataset(\"sample_submission.csv\", \"data/test\", transform=tst_transform)\n",
    "tst_loader = DataLoader(tst_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "# 베스트 모델 로드\n",
    "model.load_state_dict(torch.load(\"./model_resnet50fin_best.pt\"))  # 저장한 모델 로드\n",
    "model.to(device)  # 모델을 장치로 이동\n",
    "\n",
    "# 예측 리스트 초기화\n",
    "preds_list = []\n",
    "\n",
    "# 모델을 평가 모드로 설정\n",
    "model.eval()\n",
    "for image, _ in tqdm(tst_loader):\n",
    "    image = image.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model(image)\n",
    "\n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "\n",
    "# 결과 DataFrame 생성\n",
    "pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list\n",
    "\n",
    "# 샘플 제출 파일 로드 및 확인\n",
    "sample_submission_df = pd.read_csv(\"sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()\n",
    "\n",
    "# 예측 결과를 CSV 파일로 저장\n",
    "pred_df.to_csv(\"pred_model_best.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋 로드\n",
    "tst_dataset = ImageDataset(\"data/sample_submission.csv\", \"data/test\", transform=tst_transform)\n",
    "tst_loader = DataLoader(tst_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# 베스트 모델 로드\n",
    "model.load_state_dict(torch.load(\"./model_name_last.pt\"))  # 저장한 모델 로드\n",
    "model.to(device)  # 모델을 장치로 이동\n",
    "\n",
    "# 예측 리스트 초기화\n",
    "preds_list = []\n",
    "\n",
    "# 모델을 평가 모드로 설정\n",
    "model.eval()\n",
    "for image, _ in tqdm(tst_loader):\n",
    "    image = image.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model(image)\n",
    "\n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "\n",
    "# 결과 DataFrame 생성\n",
    "pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list\n",
    "\n",
    "# 샘플 제출 파일 로드 및 확인\n",
    "sample_submission_df = pd.read_csv(\"data2/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()\n",
    "\n",
    "# 예측 결과를 CSV 파일로 저장\n",
    "pred_df.to_csv(\"pred_model_last.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
