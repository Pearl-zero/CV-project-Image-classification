{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델: swin_tiny_patch4_window7_224\n",
    "\n",
    "데이터 100% + 온라인 어그멘테이션 배치에 따라 적용\n",
    "\n",
    "이미지 사이즈 224\n",
    "\n",
    "폴드 5개\n",
    "\n",
    "에폭 10번"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요한 라이브러리 임포트\n",
    " \n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스를 정의\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None):\n",
    "        self.df = pd.read_csv(csv).values # CSV 파일에서 데이터 로드\n",
    "        self.path = path # 이미지 파일 경로\n",
    "        self.transform = transform # 데이터 변환 함수\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) # 데이터셋의 길이 반환\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx] # 이미지 이름과 타겟 레이블 추출\n",
    "        img = np.array(Image.open(os.path.join(self.path, name))) # 이미지 로드\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image'] # 변환 적용\n",
    "        return img, target # 이미지와 레이블 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 시드 고정: 결과 재현성을 위해 시드를 고정\n",
    "\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED) # 해시 시드 고정\n",
    "random.seed(SEED) # 파이썬 랜덤 시드 고정\n",
    "np.random.seed(SEED) # NumPy 랜덤 시드 고정\n",
    "torch.manual_seed(SEED) # PyTorch CPU 시드 고정\n",
    "torch.cuda.manual_seed(SEED) # PyTorch CUDA 시드 고정\n",
    "torch.cuda.manual_seed_all(SEED) # 모든 GPU에 대한 PyTorch CUDA 시드 고정\n",
    "torch.backends.cudnn.benchmark = True # CUDA의 성능 최적화\n",
    "\n",
    "# 이미지 크기 및 변환 설정\n",
    "img_size = 224\n",
    "\n",
    "# augmentation을 위한 transform 코드\n",
    "trn_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# test image 변환을 위한 transform 코드\n",
    "tst_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "#데이터 로딩 최적화\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "def create_data_loaders(full_dataset, indices, batch_size=8, num_workers=4):\n",
    "    sampler = SubsetRandomSampler(indices)\n",
    "    return DataLoader(\n",
    "        full_dataset,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True  # GPU 메모리 전송 속도 향상\n",
    "    )\n",
    "\n",
    "def get_subset_indices(total_size, percentage):\n",
    "    \"\"\"데이터셋의 특정 비율만큼의 인덱스를 반환\"\"\"\n",
    "    indices = np.random.permutation(total_size)\n",
    "    subset_size = int(total_size * percentage)\n",
    "    return indices[:subset_size]\n",
    "\n",
    "\"\"\"\n",
    "온라인 어그멘테이션을 위한 작업\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#온라인 어그멘테이션\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "    \n",
    "def mixup_loss(loss_fn, pred, labels_a, labels_b, lam):\n",
    "    return lam * loss_fn(pred, labels_a) + (1 - lam) * loss_fn(pred, labels_b)\n",
    "\n",
    "\n",
    "def cutout(x, n_holes=1, length=50):\n",
    "    \"\"\"\n",
    "    텐서에 cutout을 적용합니다.\n",
    "    Args:\n",
    "        x: 입력 텐서 (B, C, H, W)\n",
    "        n_holes: 구멍의 개수\n",
    "        length: 구멍의 길이\n",
    "    \"\"\"\n",
    "    x = x.clone()\n",
    "    b, c, h, w = x.shape\n",
    "    \n",
    "    for i in range(b):\n",
    "        # 각 이미지마다 mask 생성\n",
    "        mask = torch.ones((h, w), device=x.device)\n",
    "        \n",
    "        for _ in range(n_holes):\n",
    "            # 랜덤 위치 선택\n",
    "            y = torch.randint(h, (1,), device=x.device)\n",
    "            x_pos = torch.randint(w, (1,), device=x.device)\n",
    "            \n",
    "            # 영역 계산\n",
    "            y1 = torch.clamp(y - length // 2, 0, h)\n",
    "            y2 = torch.clamp(y + length // 2, 0, h)\n",
    "            x1 = torch.clamp(x_pos - length // 2, 0, w)\n",
    "            x2 = torch.clamp(x_pos + length // 2, 0, w)\n",
    "            \n",
    "            # 마스크에 구멍 뚫기\n",
    "            mask[y1:y2, x1:x2] = 0\n",
    "        \n",
    "        # 모든 채널에 마스크 적용\n",
    "        mask = mask.expand(c, h, w)\n",
    "        x[i] = x[i] * mask\n",
    "    \n",
    "    return x\n",
    "\n",
    "def cutmix(x, y, beta=1.0):\n",
    "    \"\"\"배치 단위로 cutmix를 적용합니다.\"\"\"\n",
    "    batch_size = x.size()[0]\n",
    "    lam = np.random.beta(beta, beta)\n",
    "    \n",
    "    # 랜덤하게 이미지 인덱스를 섞음\n",
    "    rand_index = torch.randperm(batch_size, device=x.device)\n",
    "    \n",
    "    # target a와 b\n",
    "    y_a = y\n",
    "    y_b = y[rand_index]\n",
    "    \n",
    "    # 이미지 크기\n",
    "    _, _, h, w = x.size()\n",
    "    \n",
    "    # random 영역 선택\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(w * cut_rat)\n",
    "    cut_h = int(h * cut_rat)\n",
    "    \n",
    "    # 랜덤 중심점\n",
    "    cx = torch.randint(w, (1,), device=x.device)\n",
    "    cy = torch.randint(h, (1,), device=x.device)\n",
    "    \n",
    "    # 영역 좌표\n",
    "    x1 = torch.clamp(cx - cut_w // 2, 0, w)\n",
    "    x2 = torch.clamp(cx + cut_w // 2, 0, w)\n",
    "    y1 = torch.clamp(cy - cut_h // 2, 0, h)\n",
    "    y2 = torch.clamp(cy + cut_h // 2, 0, h)\n",
    "    \n",
    "    # 이미지 혼합\n",
    "    mixed_x = x.clone()\n",
    "    mixed_x[:, :, y1:y2, x1:x2] = x[rand_index, :, y1:y2, x1:x2]\n",
    "    \n",
    "    # 면적 비율 계산\n",
    "    lam = 1 - ((x2 - x1) * (y2 - y1) / (w * h))\n",
    "    \n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 에폭당 학습을 위한 함수\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    model.train() # 모델을 학습 모드로 설정\n",
    "    train_loss = 0\n",
    "    preds_list = [] # 예측 결과 리스트 초기화\n",
    "    targets_list = [] # 타겟 리스트 초기화\n",
    "\n",
    "    pbar = tqdm(loader) # 진행 상황을 표시하기 위한 tqdm    \n",
    "    for batch_idx, (image, targets) in enumerate(pbar): \n",
    "        image = image.to(device) # 이미지 텐서를 지정한 장치로 이동\n",
    "        targets = targets.to(device) # 타겟 텐서를 지정한 장치로 이동\n",
    "\n",
    "        model.zero_grad(set_to_none=True) # 그래디언트 초기화\n",
    "\n",
    "        # augmentation 선택: 15배치마다 순환 (5: mixup, 10: cutout, 15: cutmix)\n",
    "        if (batch_idx + 1) % 9 == 3:  # mixup\n",
    "            mixed_images, targets_a, targets_b, lam = mixup_data(image, targets)\n",
    "            preds = model(mixed_images)\n",
    "            loss = mixup_loss(criterion, preds, targets_a, targets_b, lam)\n",
    "                \n",
    "            # 평가를 위한 원본 이미지 예측\n",
    "            with torch.no_grad():\n",
    "                real_preds = model(image)\n",
    "                preds_list.extend(real_preds.argmax(dim=1).detach().cpu().numpy())\n",
    "                targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        elif (batch_idx + 1) % 9 == 6:  # cutout\n",
    "            cutout_images = cutout(image, n_holes=1, length=30)\n",
    "            preds = model(cutout_images)\n",
    "            loss = criterion(preds, targets)\n",
    "                \n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        elif (batch_idx + 1) % 9 == 0:  # cutmix\n",
    "            mixed_images, targets_a, targets_b, lam = cutmix(image, targets)\n",
    "            preds = model(mixed_images)\n",
    "            loss = mixup_loss(criterion, preds, targets_a, targets_b, lam)\n",
    "                \n",
    "            # 평가를 위한 원본 이미지 예측\n",
    "            with torch.no_grad():\n",
    "                real_preds = model(image)\n",
    "                preds_list.extend(real_preds.argmax(dim=1).detach().cpu().numpy())\n",
    "                targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        # 일반적인 학습\n",
    "        else:\n",
    "            preds = model(image) # 모델 예측\n",
    "            loss = loss_fn(preds, targets) # 손실 계산\n",
    "                   \n",
    "        loss.backward() # 역전파\n",
    "        optimizer.step() # 최적화 단계\n",
    "\n",
    "        train_loss += loss.item() # 손실 누적\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy()) # 예측 결과 추가\n",
    "        targets_list.extend(targets.detach().cpu().numpy()) # 타겟 추가\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\") # 진행 바에 손실 출력\n",
    "\n",
    "    train_loss /= len(loader) # 평균 손실 계산\n",
    "    train_acc = accuracy_score(targets_list, preds_list) # 정확도 계산\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro') # F1 점수 계산\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss, # 평균 손실\n",
    "        \"train_acc\": train_acc, # 정확도\n",
    "        \"train_f1\": train_f1, # F1 점수\n",
    "    }\n",
    "\n",
    "    return ret # 결과 반환\n",
    "\n",
    "def validation(model, val_loader, loss_fn):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for val_images, val_labels in val_loader:\n",
    "            val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
    "            val_outputs = model(val_images)\n",
    "            loss = loss_fn(val_outputs, val_labels)\n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(val_outputs.argmax(dim=1).cpu().numpy())\n",
    "            targets_list.extend(val_labels.cpu().numpy())\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "    \n",
    "    return val_loss, val_acc, val_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# 경로 설정\n",
    "csv_path = '/data/ephemeral/home/exp5/data/train_with_aug.csv'\n",
    "img_path = '/data/ephemeral/home/exp5/data/train'\n",
    "\n",
    "# MLflow 관련 파라미터 설정\n",
    "model_name = 'swin_tiny_patch4_window7_224'\n",
    "run_name = 'swin_tiny_augmentation'  # MLflow run 이름\n",
    "# learning_rate = 1e-3  # 학습률\n",
    "pretrained = True  # 사전학습 모델 사용 여부\n",
    "epochs = 10\n",
    "# BATCH_SIZE = 8\n",
    "\n",
    "# 학습 파라미터 설정\n",
    "num_workers = 4\n",
    "dropout = 0.2\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri('/data/ephemeral/home/exp/mlruns')\n",
    "mlflow.set_experiment('Docu classification5')\n",
    "\n",
    "def run_kfold_experiment(full_dataset, data_percentage, n_splits=5,  min_val_acc=0.5):\n",
    "    \"\"\"K-fold 교차 검증을 수행하는 함수\"\"\"\n",
    "    # 전체 데이터셋 크기의 특정 비율만 사용\n",
    "    total_size = len(full_dataset)\n",
    "    subset_indices = get_subset_indices(total_size, data_percentage)\n",
    "    \n",
    "    # 라벨 추출 (full_dataset의 DataFrame 사용)\n",
    "    labels = full_dataset.df[subset_indices, 1].astype(int)  # 두 번째 열이 라벨\n",
    "    \n",
    "    # StratifiedKFold 설정\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_results = []\n",
    "          \n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        # Log parameters\n",
    "        mlflow.log_params({\n",
    "                \"model_name\": model_name,\n",
    "                \"learning_rate\": learning_rate,\n",
    "                \"epochs\": epochs,\n",
    "                \"batch_size\": BATCH_SIZE,\n",
    "                \"img_size\": img_size,\n",
    "                \"pretrained\": pretrained,\n",
    "            })    \n",
    "\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(subset_indices, labels), 1):\n",
    "            print(f\"\\nFold {fold}/{n_splits}\")\n",
    "            \n",
    "            # 데이터 로더 생성\n",
    "            train_loader = create_data_loaders(full_dataset, subset_indices[train_idx], batch_size=BATCH_SIZE)\n",
    "            val_loader = create_data_loaders(full_dataset, subset_indices[val_idx], batch_size=BATCH_SIZE)\n",
    "            \n",
    "            best_val_loss = float('inf')\n",
    "            patience = 5\n",
    "            early_stop_counter = 0\n",
    "            fold_metrics = []\n",
    "            \n",
    "            for epoch in range(EPOCHS):\n",
    "                # 학습\n",
    "                train_results = train_one_epoch(train_loader, model, optimizer, loss_fn, device)\n",
    "                # 검증\n",
    "                val_loss, val_accuracy, val_f1 = validation(model, val_loader, loss_fn)\n",
    "                \n",
    "                # 첫 에폭에서 최소 성능 체크\n",
    "                if epoch == 0 and val_accuracy < min_val_acc:\n",
    "                    print(f\"Initial validation accuracy ({val_accuracy:.4f}) below threshold ({min_val_acc})\")\n",
    "                    print(\"Stopping training for this fold...\")\n",
    "                    break\n",
    "\n",
    "                # 현재 에폭 결과 저장\n",
    "                metrics = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'train_loss': train_results['train_loss'],\n",
    "                    'train_acc': train_results['train_acc'],\n",
    "                    'train_f1': train_results['train_f1'],\n",
    "                    'val_loss': val_loss,\n",
    "                    'val_acc': val_accuracy,\n",
    "                    'val_f1': val_f1\n",
    "                }\n",
    "                fold_metrics.append(metrics)\n",
    "                \n",
    "                # 결과 출력\n",
    "                print(f\"Epoch [{epoch + 1}/{EPOCHS}]\")\n",
    "                print(f\"Train Loss: {train_results['train_loss']:.4f}, \"\n",
    "                    f\"Train Acc: {train_results['train_acc']:.4f}, \"\n",
    "                    f\"Train F1: {train_results['train_f1']:.4f}\")\n",
    "                print(f\"Val Loss: {val_loss:.4f}, \"\n",
    "                    f\"Val Acc: {val_accuracy:.4f}, \"\n",
    "                    f\"Val F1: {val_f1:.4f}\")\n",
    "                \n",
    "                # Early stopping 체크\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    torch.save(model.state_dict(), f\"model_fold{fold}_best.pth\")\n",
    "                    early_stop_counter = 0\n",
    "                else:\n",
    "                    early_stop_counter += 1\n",
    "                    \n",
    "                if early_stop_counter >= patience:\n",
    "                    print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "                    break\n",
    "            \n",
    "            fold_results.append(fold_metrics)\n",
    "    \n",
    "    return fold_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset...\n",
      "Dataset created with 147616 samples\n",
      "\n",
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0109: 100%|██████████| 3691/3691 [07:38<00:00,  8.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]\n",
      "Train Loss: 0.3885, Train Acc: 0.8763, Train F1: 0.8758\n",
      "Val Loss: 0.0539, Val Acc: 0.9825, Val F1: 0.9826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0045: 100%|██████████| 3691/3691 [07:38<00:00,  8.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10]\n",
      "Train Loss: 0.2391, Train Acc: 0.9234, Train F1: 0.9233\n",
      "Val Loss: 0.0311, Val Acc: 0.9895, Val F1: 0.9895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0023: 100%|██████████| 3691/3691 [07:38<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10]\n",
      "Train Loss: 0.2104, Train Acc: 0.9299, Train F1: 0.9298\n",
      "Val Loss: 0.0249, Val Acc: 0.9928, Val F1: 0.9928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2446: 100%|██████████| 3691/3691 [07:38<00:00,  8.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10]\n",
      "Train Loss: 0.2007, Train Acc: 0.9312, Train F1: 0.9311\n",
      "Val Loss: 0.0211, Val Acc: 0.9938, Val F1: 0.9938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0019: 100%|██████████| 3691/3691 [07:38<00:00,  8.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10]\n",
      "Train Loss: 0.1868, Train Acc: 0.9375, Train F1: 0.9374\n",
      "Val Loss: 0.0277, Val Acc: 0.9907, Val F1: 0.9908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0077: 100%|██████████| 3691/3691 [07:38<00:00,  8.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10]\n",
      "Train Loss: 0.1858, Train Acc: 0.9363, Train F1: 0.9363\n",
      "Val Loss: 0.0135, Val Acc: 0.9962, Val F1: 0.9962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0011: 100%|██████████| 3691/3691 [07:39<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10]\n",
      "Train Loss: 0.1790, Train Acc: 0.9369, Train F1: 0.9369\n",
      "Val Loss: 0.0133, Val Acc: 0.9964, Val F1: 0.9964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0016: 100%|██████████| 3691/3691 [07:39<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10]\n",
      "Train Loss: 0.1785, Train Acc: 0.9352, Train F1: 0.9351\n",
      "Val Loss: 0.0179, Val Acc: 0.9942, Val F1: 0.9942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0010: 100%|██████████| 3691/3691 [07:39<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10]\n",
      "Train Loss: 0.1720, Train Acc: 0.9394, Train F1: 0.9393\n",
      "Val Loss: 0.0118, Val Acc: 0.9959, Val F1: 0.9959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0023: 100%|██████████| 3691/3691 [07:39<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10]\n",
      "Train Loss: 0.1703, Train Acc: 0.9385, Train F1: 0.9385\n",
      "Val Loss: 0.0170, Val Acc: 0.9951, Val F1: 0.9951\n",
      "\n",
      "Fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0445: 100%|██████████| 3691/3691 [07:37<00:00,  8.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]\n",
      "Train Loss: 0.1712, Train Acc: 0.9411, Train F1: 0.9410\n",
      "Val Loss: 0.0051, Val Acc: 0.9983, Val F1: 0.9983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0016: 100%|██████████| 3691/3691 [07:44<00:00,  7.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10]\n",
      "Train Loss: 0.1688, Train Acc: 0.9420, Train F1: 0.9420\n",
      "Val Loss: 0.0035, Val Acc: 0.9987, Val F1: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0013: 100%|██████████| 3691/3691 [07:39<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10]\n",
      "Train Loss: 0.1674, Train Acc: 0.9452, Train F1: 0.9451\n",
      "Val Loss: 0.0041, Val Acc: 0.9991, Val F1: 0.9991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0016:  70%|███████   | 2585/3691 [05:22<02:14,  8.21it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "model = timm.create_model(\n",
    "        model_name, \n",
    "        pretrained=True, \n",
    "        num_classes=17,\n",
    "        drop_rate=dropout\n",
    "    ).to(device)\n",
    "\n",
    "# 학습 관련 파라미터\n",
    "learning_rate = 1e-4  # 1e-3에서 낮춤\n",
    "BATCH_SIZE = 32  # 8에서 증가\n",
    "weight_decay = 1e-5  # L2 정규화 추가\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "#데이터셋 생성\n",
    "print(\"Creating dataset...\")\n",
    "full_dataset = ImageDataset(csv=csv_path, path=img_path, transform=trn_transform)\n",
    "print(f\"Dataset created with {len(full_dataset)} samples\")\n",
    "\n",
    "results = run_kfold_experiment(full_dataset, data_percentage=50, min_val_acc=0.5) \n",
    "torch.save(model.state_dict(), f\"./model_swin_tiny_augup.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋 로드\n",
    "tst_dataset = ImageDataset(\"/data/ephemeral/home/exp5/data/sample_submission.csv\", \n",
    "\"/data/ephemeral/home/exp5/data/test\", transform=tst_transform)\n",
    "tst_loader = DataLoader(tst_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# 베스트 모델 로드\n",
    "model.load_state_dict(torch.load(\"/data/ephemeral/home/exp6/model_fold1_best.pth\"))  # 저장한 모델 로드\n",
    "model.to(device)  # 모델을 장치로 이동\n",
    "\n",
    "# 예측 리스트 초기화\n",
    "preds_list = []\n",
    "\n",
    "# 모델을 평가 모드로 설정\n",
    "model.eval()\n",
    "for image, _ in tqdm(tst_loader):\n",
    "    image = image.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model(image)\n",
    "\n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "\n",
    "# 결과 DataFrame 생성\n",
    "pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list\n",
    "\n",
    "# 샘플 제출 파일 로드 및 확인\n",
    "sample_submission_df = pd.read_csv(\"/data/ephemeral/home/dataset/data/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()\n",
    "\n",
    "# 예측 결과를 CSV 파일로 저장\n",
    "pred_df.to_csv(\"fold1_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
